#textbook-intro-to-statistical-learning 

- We need to quantify the extent to which the predicted response value for a given observation is close to the true response value for that observation. 
- In the regression setting, the most commonly-used measure is the mean squared error (MSE)
$$MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{f}(x_i))^2$$
* In general, we don’t really care how well the method works on the training data. Instead, we’re interested in the accuracy of predictions on data that was previously unseen by the model.

## Overfitting

- As the flexibility of the statistical method increases, we tend to observe the accuracy over the training set trending monotonically downwards; whereas the accuracy over the test set will decrease initially but hit an inflection point and then increase.
	- This is a fundamental property of statistical learning.
	- When the model has a low MSE for the training data but a high test MSE, the model is said to be *overfitting* the data.
	- This may happen because the statistical learning algorithm is working too hard to find patterns in the training data, and may be picking up patterns that are caused by random chance instead of the true properties of $f$.
	- We generally expect the training MSE to be lower than the test MSE regardless of if overfitting has occurred because the model seeks to minimise MSE on the training set.

> [!info] From the exercises...
> Ceteris paribus, the following make a dataset more prone to overfitting:
> - **A smaller dataset**: this makes the model more likely to fit to the noise as opposed to the true $f$ signal simply due to datapoints that may be missing
> - **A larger amount of predictors**: this provides a larger number of potential relationships between predictors and response, meaning that the chance that the model will pick up on a spurious relationship is increased
> - **Higher variance in the irreducible error**: this makes it easier for a flexible model to incorrectly classify changes in the irreducible error as relationships with the outcome variable

- Methods will be discussed later for picking the correct training/test sets to most accurately find which model minimises test MSE. This will include methods such as [[cross-validation]].
