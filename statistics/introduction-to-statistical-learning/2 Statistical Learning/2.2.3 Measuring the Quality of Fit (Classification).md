#textbook_intro-to-statistical-learning

- The concepts discussed so far (like the bias-variance trade-off) apply to both regression and classification problems, albeit with some differences. 
- In classification problems, the output ($y_i$) is a category or class label instead of a number. 
- The training error rate is a common measure of the model accuracy in classification. It quantifies the proportion of the training data that the model misclassifies:
  - Suppose we seek to estimate $f$ on the basis of training observations $\{(x_1, y_1), … , (x_n, y_n)\}$ where now $y_1, y_2, … , y_n$  are qualitative. The most common approach for quantifying the accuracy of our estimate $\hat{f}$ is the training error rate, the proportion of mistakes that are made if we apply our estimate $\hat{f}$ to the training observations: 
$$\frac{1}{n} \sum_{i=1}^{n} I(y_i \neq \hat{y}_i)$$
  - Here $\hat{y}_i$ is the predicted class label for the $i$th observation using $\hat{f}$. $I(y_i \neq \hat{y}_i)$ is an indicator variable that equals 1 if $y_i \neq \hat{y}_i$ (incorrect classification), and zero if $y_i = \hat{y}_i$ (correct classification). 
    - The test error rate is notated as: $Ave(I(y_i \neq \hat{y}_i))$
