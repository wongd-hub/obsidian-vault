#textbook-intro-to-statistical-learning 

- The Bayes Classifier minimises the test error rate by assigning each observation to the most likely class, given its predictor values. This is based on the conditional probability: 
$$\Pr(Y = j | X = x_0)$$
  - Which is the probability that Y = j, given the observed predictor vector $x_0$. 

- In a two-class problem where there are only two possible response values, say class 1 or class 2, the Bayes classifier corresponds to predicting class one if $Pr(Y = 1|X = x_0) > 0.5$, and class two otherwise. 
  - In this case, the Bayes decision boundary is the set of points where the probability of belonging to one class or another is exactly 50%. 

- The Bayes classifier produces the lowest possible test error rate, known as the Bayes error rate. The error rate at $X = x_0$ is $1−max_j Pr(Y = j|X = x_0)$.
  - In general, the overall Bayes error rate is given by:
  $$ \text{{Bayes Error Rate}} = 1 - E\left[\max_j Pr(Y = j|X)\right] $$   
  - Where the expectation averages the probability over all possible values of $X$. 

- For our simulated data example, the Bayes error rate is 0.133. It is greater than zero, because the classes overlap in the true population so $\max_j Pr(Y = j|X = x_0) < 1$ for some values of $x_0$. The Bayes error rate is analogous to the [[2.2.2 The Bias-Variance Trade-Off#^3872be|irreducible error]]. 
  
- The Bayes classifier is the theoretical gold standard for predicting qualitative responses, but it’s often impossible to compute for real data because we don’t know the conditional distribution of Y given X.

